# Create a set of unique words in the corpus
unique_words = set()
for sentence in corpus:
	for word in sentence.split():
		unique_words.add(word.lower())
print(unique_words)


# Create a dictionary to map each
# unique word to an index
word_to_index = {}
for i, word in enumerate(unique_words):
	word_to_index[word] = i
print(word_to_index)

# Create one-hot encoded vectors for
# each word in the corpus
one_hot_vectors = []
for sentence in corpus:
	sentence_vectors = []
	for word in sentence.split():
		vector = np.zeros(len(unique_words))
		vector[word_to_index[word.lower()]] = 1
		sentence_vectors.append(vector)
	one_hot_vectors.append(sentence_vectors)

# Print the one-hot encoded vectors 
# for the first sentence
print("One-hot encoded vectors for the first sentence:")
for vector in one_hot_vectors[0]:
	print(vector)
